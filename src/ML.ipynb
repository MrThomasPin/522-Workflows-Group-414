{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Plotting\n",
    "import altair as alt\n",
    "\n",
    "X_train = pd.read_csv(\"data/clean-data/Xtrain-clean-autism-screening.csv\", index_col=0)\n",
    "y_train = pd.read_csv(\"data/clean-data/ytrain-clean-autism-screening.csv\", index_col=0)\n",
    "X_test = pd.read_csv(\"data/clean-data/Xtest-clean-autism-screening.csv\", index_col=0)\n",
    "y_test = pd.read_csv(\"data/clean-data/ytest-clean-autism-screening.csv\", index_col=0)\n",
    "\n",
    "\n",
    "# Make validation set \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=414)\n",
    "\n",
    "numeric_features = [\"age\", \n",
    "                    \"result\"]\n",
    "\n",
    "one_hot_features = [\"gender\", \n",
    "                    \"ethnicity\", \n",
    "                    \"jaundice\", \n",
    "                    \"country_of_res\", \n",
    "                    \"used_app_before\", \n",
    "                    \"age_desc\", \n",
    "                    \"relation\",\n",
    "                    \"Class/ASD\"]\n",
    "\n",
    "other_columns = list(X_train.columns[0:10])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(sparse_threshold=0,\n",
    "    transformers=[\n",
    "        (\"scale\", \n",
    "         StandardScaler(), \n",
    "         numeric_features),\n",
    "        (\"one_hot\", \n",
    "         OneHotEncoder(drop=None, \n",
    "                       handle_unknown=\"ignore\"), \n",
    "         one_hot_features)\n",
    "    ])\n",
    "\n",
    "X_train_temp = pd.DataFrame(preprocessor.fit_transform(X_train), \n",
    "            index = X_train.index,\n",
    "            columns = (numeric_features + \n",
    "                       list(preprocessor\n",
    "                           .named_transformers_[\"one_hot\"]\n",
    "                           .get_feature_names(one_hot_features)))\n",
    "                      )\n",
    "\n",
    "X_test_temp = pd.DataFrame(preprocessor.transform(X_test),\n",
    "                     index = X_test.index,\n",
    "                     columns = X_train_temp.columns)\n",
    "\n",
    "X_valid_temp = pd.DataFrame(preprocessor.transform(X_valid),\n",
    "                     index = X_valid.index,\n",
    "                     columns = X_train_temp.columns)\n",
    "\n",
    "X_train = X_train_temp.join(X_train[other_columns])\n",
    "X_test = X_test_temp.join(X_test[other_columns])\n",
    "X_valid = X_valid_temp.join(X_valid[other_columns])\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train.to_numpy().ravel())\n",
    "y_test = le.transform(y_test.to_numpy().ravel())\n",
    "y_valid = le.transform(y_valid.to_numpy().ravel())\n",
    "\n",
    "## Trying Gridsearch on different models to find best\n",
    "\n",
    "## Initialize models\n",
    "lr = LogisticRegression()\n",
    "dt = DecisionTreeClassifier(random_state=414)\n",
    "rf = RandomForestClassifier(random_state=414)\n",
    "svm = SVC(random_state=414)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Make list for models and a list to store their values\n",
    "estimators = [lr, dt, rf, svm, knn]\n",
    "best_parameters = []\n",
    "best_precision_scores = []\n",
    "\n",
    "# Make list of dictionaries for parameters\n",
    "params = [{'C':[0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "         'penalty': ['l1', 'l2']},\n",
    "         {'max_depth': [1, 5, 10, 15, 20, 25, None],\n",
    "         'max_features': [3, 5, 10, 20, 25, 50, 100, None]},\n",
    "         {'min_impurity_decrease': [0, 0.25, 0.5],\n",
    "         'max_features': [3, 5, 10, 20, 50, 100, 'auto']},\n",
    "         {'C':[0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "         'gamma':[0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "         {'n_neighbors': [2, 5, 10, 15, 20, 50, 100],\n",
    "         'algorithm': ['auto', 'brute']}]\n",
    "\n",
    "# Run for loop to best parameters for each model\n",
    "# Scoring = recall to reduce false positives\n",
    "for i in range(len(estimators)):\n",
    "    search = GridSearchCV(estimator=estimators[i], \n",
    "                          param_grid=params[i],\n",
    "                          cv = 10,\n",
    "                          n_jobs=-1,\n",
    "                         scoring='recall')\n",
    "    \n",
    "    search_object = search.fit(X_train, y_train)\n",
    "    \n",
    "    # Store the output on each iteration\n",
    "    best_parameters.append(search_object.best_params_)\n",
    "    best_precision_scores.append(search_object.best_score_)\n",
    "\n",
    "best_parameters[np.argmax(best_precision_scores)]\n",
    "\n",
    "\n",
    "# the best precision score comes from a decision tree classifier with max_depth=15 and max_features=100\n",
    "# and precision = 0.46\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=15, max_features=100)\n",
    "dt.fit(X_train, y_train).score(X_train, y_train)\n",
    "\n",
    "\n",
    "# It gets almost perfect on the train set\n",
    "\n",
    "dt.score(X_valid, y_valid)\n",
    "\n",
    "# and ~81% on the validation set\n",
    "\n",
    "prelim_matrix = pd.DataFrame(confusion_matrix(y_valid, dt.predict(X_valid)))\n",
    "\n",
    "\n",
    "preliminary_matrix = prelim_matrix.rename(columns={0:\"predicted no\", 1:'predicted yes'}, \n",
    "                  index={0:\"actual no\", 1:'actual yes'}).swapaxes(0,1)\n",
    "\n",
    "preliminary_matrix.to_csv('data/preliminary_matrix.csv')\n",
    "\n",
    "#print(classification_report(y_test, dt.predict(X_test)))\n",
    "\n",
    "## Subset just the questions:\n",
    "\n",
    "questions = ['A1_Score',\n",
    "       'A2_Score',\n",
    "       'A3_Score',\n",
    "       'A4_Score',\n",
    "       'A5_Score',\n",
    "       'A6_Score',\n",
    "       'A7_Score',\n",
    "       'A8_Score',\n",
    "       'A9_Score',\n",
    "       'A10_Score']\n",
    "\n",
    "questions_train_df = X_train[questions]\n",
    "\n",
    "questions_valid_df = X_valid[questions]\n",
    "\n",
    "questions_test_df = X_test[questions]\n",
    "\n",
    "\n",
    "\n",
    "# Attribution: Varada Kolhatkar\n",
    "\n",
    "class ForwardSelection:\n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 min_features=None, \n",
    "                 max_features=None, \n",
    "                 scoring=None, \n",
    "                 cv=None):\n",
    "        \"\"\"\n",
    "        WRITE YOUR DOCSTRING\n",
    "        \"\"\"\n",
    "        self.max_features = max_features\n",
    "        if min_features is None:\n",
    "            self.min_features = 1\n",
    "        else:\n",
    "            self.min_features = min_features\n",
    "\n",
    "        self.model = model\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv\n",
    "        self.ftr_ = []\n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        WRITE YOUR DOCSTRING        \n",
    "        \"\"\"\n",
    "        \n",
    "        error = np.inf\n",
    "        best = None\n",
    "        feature_index = list(range(0, (X.shape[1])))\n",
    "        errors = []\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=514)\n",
    "\n",
    "        X_temp = X_train\n",
    "\n",
    "        while error > 0.0:\n",
    "            if best is not None:\n",
    "                if best not in feature_index:\n",
    "                    del feature_index[-2]\n",
    "                    break\n",
    "                feature_index.remove(best)\n",
    "\n",
    "            for i in feature_index:\n",
    "                self.model.fit(X_temp[:, self.ftr_ + [i]], y_train)\n",
    "                temp_error = 1-np.mean(cross_val_score(self.model, X[:, self.ftr_ + [i]], y, scoring='f1'))\n",
    "\n",
    "                if temp_error < error:\n",
    "                    error = temp_error\n",
    "                    best = i\n",
    "\n",
    "            errors.append(round(error, 3))\n",
    "\n",
    "            if len(errors) > 2:\n",
    "                if errors[-1] >= errors[-2]:\n",
    "                    break\n",
    "\n",
    "            if self.max_features is not None:\n",
    "                if len(errors) > self.max_features:\n",
    "                    break\n",
    "\n",
    "            self.ftr_.append(best)\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        WRITE YOUR DOCSTRING        \n",
    "        \"\"\"\n",
    "        return X[:, self.ftr_]\n",
    "    \n",
    "\n",
    "fs = ForwardSelection(DecisionTreeClassifier(), max_features=None)\n",
    "\n",
    "# np.mean(cross_val_score(dt, questions_train_df, y_train, scoring='precision'))\n",
    "\n",
    "fs.fit(questions_train_df.to_numpy(), y_train)\n",
    "\n",
    "fs.ftr_\n",
    "\n",
    "# No single one question is better than any other one question so forward selection won't work\n",
    "# Or it just won't work with a decision tree\n",
    "\n",
    "\n",
    "rfe =RFE(DecisionTreeClassifier(), n_features_to_select=5)\n",
    "\n",
    "rfe.fit(questions_train_df, y_train)\n",
    "\n",
    "# The top 5 questions:\n",
    "\n",
    "top_five = np.where(rfe.ranking_ == 1)[0]\n",
    "\n",
    "X_train_best_5 = questions_train_df.to_numpy()[:,top_five]\n",
    "X_test_best_5 = questions_test_df.to_numpy()[:,top_five]\n",
    "X_valid_best_5 = questions_valid_df.to_numpy()[:,top_five]\n",
    "\n",
    "dt2 = DecisionTreeClassifier()\n",
    "\n",
    "dt2.fit(X_train_best_5, y_train)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_valid, dt2.predict(X_valid_best_5)))\n",
    "\n",
    "# Using just the top 5 questions gets a much worse result than using all the features\n",
    "\n",
    "\n",
    "# Try all questions:\n",
    "dt3 = DecisionTreeClassifier()\n",
    "\n",
    "dt3.fit(questions_train_df, y_train)\n",
    "\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, dt.predict(X_test)))\n",
    "\n",
    "final_matrix = conf_matrix.rename(columns={0:\"predicted no\", 1:'predicted yes'}, \n",
    "                  index={0:\"actual no\", 1:'actual yes'}).swapaxes(0,1)\n",
    "\n",
    "final_matrix#.to_csv('data/confusion_matrix.csv')\n",
    "\n",
    "# ROC curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, dt.predict_proba(X_test)[:,1])\n",
    "\n",
    "roc_df = pd.DataFrame({\"fpr\":fpr, \"tpr\":tpr})\n",
    "\n",
    "line_df = pd.DataFrame({\"start\":[0,1], \"end\":[0,1]})\n",
    "\n",
    "roc = alt.Chart(roc_df).mark_line().encode(\n",
    "    x = alt.X(\"fpr:Q\"),\n",
    "    y = alt.Y(\"tpr:Q\")\n",
    ")\n",
    "    \n",
    "line = alt.Chart(line_df).mark_line(strokeDash=[5,5], color=\"orange\").encode(\n",
    "    x = alt.X(\"start:Q\", axis=alt.Axis(title=\"False Positive Rate\")),\n",
    "    y = alt.Y(\"end:Q\", axis=alt.Axis(title=\"True Positive Rate\"))\n",
    ")\n",
    "    \n",
    "chart = (roc + line).configure_axis(titleFontSize=20).properties(title=\"ROC Curve\").configure_title(fontSize=20)\n",
    "\n",
    "chart\n",
    "\n",
    "chart.save('img/ROC.png', webdriver='firefox')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
